{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRObT5dxtgu0"
   },
   "source": [
    "# Become a movie director\n",
    "\n",
    "Let's use Scrapy to get some information about the 250 top rated movies on <a href=\"http://www.imdb.com/\" target=\"_blank\">IMDB</a>.\n",
    "\n",
    "1. Install `Scrapy`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a folder where you will store the scripts and results of this exercise. Create a file named `imdb1.py` in that folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Start by writing code in the script to:\n",
    "* import os, logging, scrapy, and CrawlerProcess from scrapy.crawler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a first spider called `imdb_spider` with:\n",
    "* name `imdb`\n",
    "* start_urls `https://www.imdb.com/chart/boxoffice`\n",
    "\n",
    "This spider should scrape the ranking, the title, the url, the total earnings, the rating and the number of voters for the first movie of the charts.\n",
    "\n",
    "Set up the `CrawlerProcess`.\n",
    "Save the results to a `imdb1.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 14:50:24 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: scrapybot)\n",
      "2024-12-06 14:50:24 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.10.4, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 23.10.0, Python 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 24.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 42.0.5, Platform Windows-11-10.0.22631-SP0\n",
      "2024-12-06 14:50:24 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-12-06 14:50:24 [py.warnings] WARNING: c:\\tools\\Anaconda3\\Lib\\site-packages\\scrapy\\utils\\request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2024-12-06 14:50:24 [scrapy.extensions.telnet] INFO: Telnet Password: e3a4b2bf073c74b2\n",
      "2024-12-06 14:50:24 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-12-06 14:50:24 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2024-12-06 14:50:25 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-12-06 14:50:25 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-12-06 14:50:25 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-12-06 14:50:25 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-12-06 14:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-12-06 14:50:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2024-12-06 14:50:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.imdb.com/chart/boxoffice/> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\tools\\Anaconda3\\Lib\\site-packages\\twisted\\internet\\defer.py\", line 1075, in _runCallbacks\n",
      "    current.result = callback(  # type: ignore[misc]\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\tools\\Anaconda3\\Lib\\site-packages\\scrapy\\spiders\\__init__.py\", line 79, in _parse\n",
      "    return self.parse(response, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\olivier\\exercices\\jedha\\notebook\\scrapy\\movie\\imdb1.py\", line 19, in parse\n",
      "    \"ranking\": response.xpath('/html/body/div[2]/main/div/div[3]/section/div/div[2]/div/ul/li[1]/div[2]/div/div/div/a/h3/text()').get().split(\".\")[0]\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "2024-12-06 14:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-12-06 14:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: movie/imdb1.json\n",
      "2024-12-06 14:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 429,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 147414,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/308': 1,\n",
      " 'elapsed_time_seconds': 1.340764,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 12, 6, 13, 50, 26, 910192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 747202,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/ERROR': 1,\n",
      " 'log_count/INFO': 11,\n",
      " 'log_count/WARNING': 1,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2024, 12, 6, 13, 50, 25, 569428, tzinfo=datetime.timezone.utc)}\n",
      "2024-12-06 14:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!python movie/imdb1.py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a new script called `imdb2.py` where you'll scrape the same information for all the movies in the chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 17:03:59 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
      "2023-09-27 17:03:59 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.9.16 (main, Jan 11 2023, 16:05:54) - [GCC 11.2.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1t  7 Feb 2023), cryptography 38.0.4, Platform Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31\n",
      "2023-09-27 17:03:59 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-09-27 17:03:59 [py.warnings] WARNING: /home/antoineco/miniconda3/lib/python3.9/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-09-27 17:03:59 [scrapy.extensions.telnet] INFO: Telnet Password: 200d749b78b68a0e\n",
      "2023-09-27 17:03:59 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-09-27 17:03:59 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2023-09-27 17:03:59 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-09-27 17:03:59 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-09-27 17:03:59 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-09-27 17:03:59 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-09-27 17:03:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-09-27 17:03:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-09-27 17:04:00 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-09-27 17:04:00 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: 01-Become_a_movie_director/imdb2.json\n",
      "2023-09-27 17:04:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 429,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 127850,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/308': 1,\n",
      " 'elapsed_time_seconds': 0.86681,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 9, 27, 15, 4, 0, 218022, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 666999,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/INFO': 11,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 88625152,\n",
      " 'memusage/startup': 88625152,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2023, 9, 27, 15, 3, 59, 351212, tzinfo=datetime.timezone.utc)}\n",
      "2023-09-27 17:04:00 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Optional ðŸ’ªðŸ’ª\n",
    "6. Based on the results obtained, create a list called `url_list` containing all the urls for the movies in the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ranking': '1',\n",
       "  'title': 'The Nun II',\n",
       "  'url': '/title/tt10160976/?ref_=chtbo_t_1',\n",
       "  'total_earnings': '$70M',\n",
       "  'rating': '5.9',\n",
       "  'nb_voters': '19K'},\n",
       " {'ranking': '2',\n",
       "  'title': 'Expend4bles',\n",
       "  'url': '/title/tt3291150/?ref_=chtbo_t_2',\n",
       "  'total_earnings': '$8.7M',\n",
       "  'rating': '5.2',\n",
       "  'nb_voters': '5K'},\n",
       " {'ranking': '3',\n",
       "  'title': 'A Haunting in Venice',\n",
       "  'url': '/title/tt22687790/?ref_=chtbo_t_3',\n",
       "  'total_earnings': '$26M',\n",
       "  'rating': '6.8',\n",
       "  'nb_voters': '20K'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 17:04:16 [numexpr.utils] INFO: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>total_earnings</th>\n",
       "      <th>rating</th>\n",
       "      <th>nb_voters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Nun II</td>\n",
       "      <td>/title/tt10160976/?ref_=chtbo_t_1</td>\n",
       "      <td>$70M</td>\n",
       "      <td>5.9</td>\n",
       "      <td>19K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Expend4bles</td>\n",
       "      <td>/title/tt3291150/?ref_=chtbo_t_2</td>\n",
       "      <td>$8.7M</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A Haunting in Venice</td>\n",
       "      <td>/title/tt22687790/?ref_=chtbo_t_3</td>\n",
       "      <td>$26M</td>\n",
       "      <td>6.8</td>\n",
       "      <td>20K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Equalizer 3</td>\n",
       "      <td>/title/tt17024450/?ref_=chtbo_t_4</td>\n",
       "      <td>$82M</td>\n",
       "      <td>7.1</td>\n",
       "      <td>21K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>/title/tt1517268/?ref_=chtbo_t_5</td>\n",
       "      <td>$631M</td>\n",
       "      <td>7.1</td>\n",
       "      <td>334K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ranking                 title                                url  \\\n",
       "0       1            The Nun II  /title/tt10160976/?ref_=chtbo_t_1   \n",
       "1       2           Expend4bles   /title/tt3291150/?ref_=chtbo_t_2   \n",
       "2       3  A Haunting in Venice  /title/tt22687790/?ref_=chtbo_t_3   \n",
       "3       4       The Equalizer 3  /title/tt17024450/?ref_=chtbo_t_4   \n",
       "4       5                Barbie   /title/tt1517268/?ref_=chtbo_t_5   \n",
       "\n",
       "  total_earnings rating nb_voters  \n",
       "0           $70M    5.9       19K  \n",
       "1          $8.7M    5.2        5K  \n",
       "2           $26M    6.8       20K  \n",
       "3           $82M    7.1       21K  \n",
       "4          $631M    7.1      334K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url list: ['https://www.imdb.com/title/tt10160976/?ref_=chtbo_t_1', 'https://www.imdb.com/title/tt3291150/?ref_=chtbo_t_2', 'https://www.imdb.com/title/tt22687790/?ref_=chtbo_t_3']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Store the list of urls to a file called `url_list.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape all the pages from the movies in the charts and extract the complete cast, the Storyline, and the genres, also save the title and url for future joins purposes. *Pay attention to inconsistencies between pages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 17:04:47 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
      "2023-09-27 17:04:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.9.16 (main, Jan 11 2023, 16:05:54) - [GCC 11.2.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1t  7 Feb 2023), cryptography 38.0.4, Platform Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31\n",
      "2023-09-27 17:04:47 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-09-27 17:04:47 [py.warnings] WARNING: /home/antoineco/miniconda3/lib/python3.9/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-09-27 17:04:47 [scrapy.extensions.telnet] INFO: Telnet Password: d1ce3247c5f87d50\n",
      "2023-09-27 17:04:47 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-09-27 17:04:47 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2023-09-27 17:04:47 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-09-27 17:04:47 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-09-27 17:04:47 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-09-27 17:04:47 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-09-27 17:04:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-09-27 17:04:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-09-27 17:04:51 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-09-27 17:04:51 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: 01-Become_a_movie_director/imdb3.json\n",
      "2023-09-27 17:04:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 2308,\n",
      " 'downloader/request_count': 10,\n",
      " 'downloader/request_method_count/GET': 10,\n",
      " 'downloader/response_bytes': 1816339,\n",
      " 'downloader/response_count': 10,\n",
      " 'downloader/response_status_count/200': 10,\n",
      " 'elapsed_time_seconds': 3.721095,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 9, 27, 15, 4, 51, 506967, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 10733090,\n",
      " 'httpcompression/response_count': 10,\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/INFO': 11,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 118042624,\n",
      " 'memusage/startup': 118042624,\n",
      " 'response_received_count': 10,\n",
      " 'scheduler/dequeued': 10,\n",
      " 'scheduler/dequeued/memory': 10,\n",
      " 'scheduler/enqueued': 10,\n",
      " 'scheduler/enqueued/memory': 10,\n",
      " 'start_time': datetime.datetime(2023, 9, 27, 15, 4, 47, 785872, tzinfo=datetime.timezone.utc)}\n",
      "2023-09-27 17:04:51 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-Become_movie_director_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
